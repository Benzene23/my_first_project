{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris dataset experimentation\n",
    "The Iris dataset was used in R.A. Fisher's classic 1936 paper, The Use of Multiple Measurements in Taxonomic Problems, and can also be found on the UCI Machine Learning Repository.\n",
    "\n",
    "It includes three iris species with 50 samples each as well as some properties about each flower. One flower species is linearly separable from the other two, but the other two are not linearly separable from each other.\n",
    "\n",
    "https://www.geeksforgeeks.org/exploratory-data-analysis-on-iris-dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import Necessary Libraries\n",
    "# Import libraries for data manipulation, visualization, and machine learning\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Step 0, download the data, could also be found at https://www.kaggle.com/datasets/uciml/iris\n",
    "# Once this cell has been run, the below code could be deleted safely\n",
    "from sklearn import datasets\n",
    "# Load the IRIS dataset and print to csv\n",
    "iris = datasets.load_iris()\n",
    "iris_df = pd.DataFrame(data= np.c_[iris['data'], iris['target']],\n",
    "                     columns= iris['feature_names'] + ['target'])\n",
    "iris_df.columns = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\n",
    "iris_df.to_csv('iris.csv', index=False)\n",
    "del iris_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load the IRIS Dataset\n",
    "# Load the IRIS dataset from a CSV file (hint, use the pandas read_csv function)\n",
    "# Create a DataFrame from the dataset\n",
    "\n",
    "iris_df = pd.read_csv('iris.csv')\n",
    "iris_df.head() # Display the first 5 rows of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Explore the Data\n",
    "\n",
    "Get basic information and statistics about the dataset\n",
    "- Use `.head()` to view the first few rows of the dataset\n",
    "- Use `.info()` to understand the structure of the dataset (e.g., data types, missing values)\n",
    "- Use `.describe()` to get summary statistics for each feature\n",
    "- Use `iris_df[\"<col_name>\"]` or `iris_df.col_name` to get a specific column of data (called a series in pandas)\n",
    "  \n",
    "Visualization\n",
    "- Visualize the data using scatter plots to understand relationships between features\n",
    "- Use matplotlib scatter plots to visualize relationships between specific features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: create plots of each features vs each other, colored by species. For instance, \n",
    "# this is a plot of sepal length vs sepal width:\n",
    "plt.scatter(iris_df['sepal_length'], iris_df['sepal_width'], c=iris_df['species'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: replace this cell with a *short* explanation of what you see in the plots. Be ready to expand when presenting. Example explanations might be the easiest species to differentiate, and which variables are best used for each species"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Preprocess the Data\n",
    "- Split the dataset into features and target. \n",
    "- Split the dataset into training and testing sets\n",
    "- Standard practice is to have X as capital (bc its a matrix), whereas y is lowercase, meaning its a vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = #TODO (hint: features are all columns except the last one)\n",
    "y = #TODO (hint: species is likely the last column)\n",
    "print(f'X shape: {X.shape}, y shape: {y.shape}')\n",
    "\n",
    "# TODO: Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features can be helpful for some models. This can be done manually, \n",
    "# or using StandardScaler from sklearn\n",
    "# TODO print some of the above explored graphs from section 3 before and after scaling to see the difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Train and evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Logistic Regression to classify the flowers based on their features\n",
    "# TODO: Train a Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "# TODO: Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_true = #TODO (hint, what is the true value of y that we're testing against?)\n",
    "\n",
    "# Print accuracy, confusion matrix, and classification report to evaluate model performance\n",
    "# TODO: Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO use sns.heatplot to visualize the confusion matrix\n",
    "#TODO standardize the values in the confusion matrix so that each row sums to 1\n",
    "# standardizing the confusion matrix allows us to see the ratio of correct and \n",
    "# incorrect predictions for each class as a percentage. Reminder to read the \n",
    "# Confusion Matrix article for more information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Replace this cell with a short explanation of how to interpret the confusion matrix in context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Repeat with a model of your choice\n",
    "KMeans, KNN, or Random Forest (all from sklearn) all good starting points - feel free to go wild tho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Replace this cell with a short explanation of how to interpret the confusion matrix in context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Conclusion and Next Steps\n",
    "Do the below steps, with a focus on THINKING through the results, writing them is not fully necessary. Be ready to explain your thinking however\n",
    "- Discuss the accuracy and performance of the two models\n",
    "- Discuss model performance\n",
    "- Provide suggestions for improvement or extensions, such as trying different algorithms or hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: discussion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
